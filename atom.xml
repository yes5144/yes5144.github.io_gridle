<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://yes5144.github.io/</id>
    <title>Talk is cheap. Show me the code</title>
    <updated>2019-09-17T23:16:38.919Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://yes5144.github.io/"/>
    <link rel="self" href="https://yes5144.github.io//atom.xml"/>
    <subtitle>你第十年的目标是CTO，你打算如何实现？</subtitle>
    <logo>https://yes5144.github.io//images/avatar.png</logo>
    <icon>https://yes5144.github.io//favicon.ico</icon>
    <rights>All rights reserved 2019, Talk is cheap. Show me the code</rights>
    <entry>
        <title type="html"><![CDATA[Docker入门命令]]></title>
        <id>https://yes5144.github.io//post/docker-ru-men-ming-ling</id>
        <link href="https://yes5144.github.io//post/docker-ru-men-ming-ling">
        </link>
        <updated>2019-08-26T15:22:52.000Z</updated>
        <content type="html"><![CDATA[<h3 id="docker-基础命令">Docker 基础命令</h3>
<pre><code>docker pull
docker search 
docker push
docker images
docker ps
docker create -it ubuntu:latest
docker start|stop|restart

docker run ubuntu /bin/echo 'Hello world'

docker run -it ubuntu:14.04  /bin/bash
docker ps
docker logs ID_or_name
## 列出所有容器的ID
docker ps -qa

docker exec -it id_or_name /bin/bash

docker rm id_or_name

## 导入容器
docker  export  -o test_name.tar   id_or_name
ls
docker  export id_or_name &gt; test_name.tar22
ls
## 导出容器
docker  import  test_name_tar  -  test/ubuntu:v1.0
</code></pre>
<h3 id="docker-数据管理">Docker 数据管理</h3>
<blockquote>
<p>数据卷：容器内数据直接映射到本地主机环境
数据库容器：使用特定容器维护数据卷</p>
</blockquote>
<pre><code>## 在容器内创建一个数据卷
docker run -d -P  --name web  -v /webapp  training/webapp  python app.py

docker run  -d -P --name web  -v /src/webapp:/opt/webapp  training/webapp  python  app.py

## 数据卷容器
docker run -it -v /dbdata  --name dbdata ubuntu
docker run -it --volumes-from  dbdata  --name db1 ubuntu
docker run -it --volumes-from  dbdata  --name db2 ubuntu
## 也可以从已经挂载了容器卷的容器来挂载数据卷
docker run -d --volumes-from  db1  --name db1 training/postgres

## 数据卷容器的备份
docker run --volumes-from dbdata -v ${pwd}:/backup  --name worker ubuntu  tar cvf /backup/backup.tar /dbdata

## 数据卷容器恢复
### 首先创建一个带有数据卷的容器dbdata2
docker  run -v  /dbdata  --name dbdata2 ubuntu  /bin/bash
docker  run --volumes-from dbdata2 -v ${pwd}:/backup busybox tar xvf /backup/backup.tar
</code></pre>
<h3 id="端口映射和容器互联">端口映射和容器互联</h3>
<pre><code>## -P Docker会随机映射一个49000-49900端口到容器开放的端口，-p Host_port:Container_port指定端口
docker run -d -P training/webapp python app.py
docker logs -f Name_or_ID

docker port  Name_or_ID Port

docker inspect Name_or_ID

docker inspect -f &quot;{{ .Name }}&quot; Name_or_ID
## 容器互联 --link
docker run -d --name db training/postgres

docker run -d  -P --name web --link db:db training/webapp python app.py
## --link name:alias; 其中name是连接的容器名称，alias是这个连接的别名
docker run --rm --name web2 --link db:db training/webapp env
## 父容器是什么容器？？
## 除了环境变量之外，Docker还添加host信息到父容器的/etc/hosts文件。下面是父容器webd hosts文件
docker run -it --rm --link db:db training/webapp /bin/bash

root@lkdje323k3: # cat /etc/hosts

</code></pre>
<h3 id=""></h3>
<pre><code>
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[二进制部署k8s]]></title>
        <id>https://yes5144.github.io//post/er-jin-zhi-bu-shu-k8s</id>
        <link href="https://yes5144.github.io//post/er-jin-zhi-bu-shu-k8s">
        </link>
        <updated>2019-08-18T09:35:17.000Z</updated>
        <content type="html"><![CDATA[<h3 id=""></h3>
<h3 id="部署etcd">部署etcd</h3>
<pre><code>
## 生成自签证书
curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl
curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson
curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo
chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson /usr/local/bin/cfssl-certinfo

## 创建两个证书存放目录
mkdir -p  /root/k8s/{etcd-cert,k8s-cert}
## 生成认证机构
cd  /root/k8s/etcd-cert
cat &gt; ca-config.json &lt;&lt;EOF
{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;87600h&quot;
    },
    &quot;profiles&quot;: {
      &quot;www&quot;: {
         &quot;expiry&quot;: &quot;87600h&quot;,
         &quot;usages&quot;: [
            &quot;signing&quot;,
            &quot;key encipherment&quot;,
            &quot;server auth&quot;,
            &quot;client auth&quot;
        ]
      }
    }
  }
}
EOF

cat &gt; ca-csr.json &lt;&lt;EOF
{
    &quot;CN&quot;: &quot;etcd CA&quot;,
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;L&quot;: &quot;Beijing&quot;,
            &quot;ST&quot;: &quot;Beijing&quot;
        }
    ]
}
EOF

cfssl gencert -initca ca-csr.json | cfssljson -bare ca

## 为etcd生成证书
cat &gt; server-csr.json &lt;&lt;EOF
{
    &quot;CN&quot;: &quot;etcd&quot;,
    &quot;hosts&quot;: [
    &quot;192.168.204.133&quot;,
    &quot;192.168.204.134&quot;,
    &quot;192.168.204.135&quot;
    ],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;L&quot;: &quot;BeiJing&quot;,
            &quot;ST&quot;: &quot;BeiJing&quot;
        }
    ]
}
EOF

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server

## 下载etcd二进制包开始部署
mkdir -p  /opt/etcd/{bin,cfg,ssl}
cp  /root/k8s/etcd-cert/{ca,server,server-key}.pem  /opt/etcd/ssl/
mkdir  /opt/src &amp;&amp; cd /opt/src
wget https://github.com/coreos/etcd/releases/download/v3.3.13/etcd-v3.3.13-linux-amd64.tar.gz
tar -xvf etcd-v3.3.13-linux-amd64.tar.gz
cp  etcd-v3.3.13-linux-amd64/etcd*  /opt/etcd/bin/

## etcd启动配置文件
ETCD_NAME=&quot;etcd01&quot;
ETCD_IP=&quot;192.168.204.133&quot;
ETCD_CLUSTER=&quot;etcd02=https://192.168.204.134:2380,etcd03=https://192.168.204.135:2380&quot;

cat &lt;&lt;EOF &gt;/opt/etcd/cfg/etcd
#[Member]
ETCD_NAME=&quot;${ETCD_NAME}&quot;
ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;
ETCD_LISTEN_PEER_URLS=&quot;https://${ETCD_IP}:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;https://${ETCD_IP}:2379&quot;

#[Clustering]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://${ETCD_IP}:2380&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;https://${ETCD_IP}:2379&quot;
ETCD_INITIAL_CLUSTER=&quot;etcd01=https://${ETCD_IP}:2380,${ETCD_CLUSTER}&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;
ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;
EOF

## 生成systemd启动文件
cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/etcd.service
[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
EnvironmentFile=${WORK_DIR}/cfg/etcd
ExecStart=${WORK_DIR}/bin/etcd \
--name=\${ETCD_NAME} \
--data-dir=\${ETCD_DATA_DIR} \
--listen-peer-urls=\${ETCD_LISTEN_PEER_URLS} \
--listen-client-urls=\${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \
--advertise-client-urls=\${ETCD_ADVERTISE_CLIENT_URLS} \
--initial-advertise-peer-urls=\${ETCD_INITIAL_ADVERTISE_PEER_URLS} \
--initial-cluster=\${ETCD_INITIAL_CLUSTER} \
--initial-cluster-token=\${ETCD_INITIAL_CLUSTER_TOKEN} \
--initial-cluster-state=new \
--cert-file=${WORK_DIR}/ssl/server.pem \
--key-file=${WORK_DIR}/ssl/server-key.pem \
--peer-cert-file=${WORK_DIR}/ssl/server.pem \
--peer-key-file=${WORK_DIR}/ssl/server-key.pem \
--trusted-ca-file=${WORK_DIR}/ssl/ca.pem \
--peer-trusted-ca-file=${WORK_DIR}/ssl/ca.pem
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF

## 启动
systemctl daemon-reload
systemctl enable etcd
systemctl restart etcd
</code></pre>
<h3 id="node节点部署flannel">node节点部署flannel</h3>
<pre><code>

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yum部署k8s]]></title>
        <id>https://yes5144.github.io//post/k8s-bu-shu</id>
        <link href="https://yes5144.github.io//post/k8s-bu-shu">
        </link>
        <updated>2019-08-18T07:47:13.000Z</updated>
        <content type="html"><![CDATA[<h2 id="k8s安装入门">k8s安装入门</h2>
<pre><code>### 参考链接：https://www.cnblogs.com/sxdcgaq8080/p/10621437.html

## 准备工作
192.168.204.133  k8s-master01
192.168.204.134  k8s-node01
192.168.204.135  k8s-node02

### 分别设置主机名
hostnamectl --static set-hostname  k8s-master01
hostnamectl --static set-hostname  k8s-node01
hostnamectl --static set-hostname  k8s-node02


### 修改/etc/hosts

cat &gt;&gt;/etc/hosts &lt;&lt;EOF
192.168.204.133    k8s-master01
192.168.204.133    etcd
192.168.204.133    registry
192.168.204.134    k8s-node01
192.168.204.135    k8s-node02
EOF

### 关闭防火墙，SELinux
systemctl stop firewalld.service
systemctl disable firewalld.service

### 再使用查看命令查看，如果是如下效果，说明成功
firewall-cmd --state

### ntpdate
echo '*/10 * * * * root ntpdate  ntp2.aliyun.com' &gt;&gt; /etc/crontab
</code></pre>
<h3 id="一-主节点master01">一、主节点master01</h3>
<pre><code>主节点需要安装

etcd 存储数据中心

flannel k8s的一种网络方案

kubernetes 【包含：kube-api-server  controllerManager   Scheduler 】

## 1,etcd的安装
### 1.1 命令安装
yum install -y etcd
### 1.2 配置文件
cd  /etc/etcd
cp  etcd.conf  etcd.conf.default
cat etcd.conf
ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379,http://0.0.0.0:4001&quot;
ETCD_NAME=&quot;master&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;http://etcd:2379,http://etcd:4001&quot;


### 1.3 启动etcd服务并验证
systemctl start etcd
systemctl enable etcd
systemctl status etcd

#### 检查健康状况
etcdctl -C http://etcd:2379 cluster-health
etcdctl -C http://etcd:4001 cluster-health

## 2,flannel的安装
### 2.1 安装命令


### 2.2 配置文件 /etc/sysconfig/flanneld
FLANNEL_ETCD_ENDPOINTS=&quot;http://etcd:2379&quot;
FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot;

### 2.3 配置etcd中关于flannel的key
etcdctl mk /atomic.io/network/config '{ &quot;Network&quot;: &quot;10.0.0.0/16&quot; }'

### 2.4 启动flannel服务，并设置开机自启
systemctl start flanneld.service
systemctl status flanneld.service
systemctl enable flanneld.service

## 3,安装kubernetes
### 3.1 安装命令
yum install kubernetes

### 3.2安装后，需要修改配置
### 配置修改是为了下面这些需要运行的组件
kube-api-server
kuber-scheduler
kube-controller-manager

vim /etc/kubernetes/apiserver

vim /etc/kubernetes/config


### 3.3 分别启动三个组件服务，并且设置为自启动
systemctl start kube-apiserver.service
systemctl start kube-controller-manager.service
systemctl start kube-scheduler.service


systemctl enable kube-apiserver.service
systemctl enable kube-controller-manager.service
systemctl enable kube-scheduler.service


## 4,安装docker
### 4.1 安装docker命令：
yum install  -y docker 
### 4.2 启动docker服务命令：
service docker start
### 4.3 docker加入自启动服务命令：
chkconfig docker on

</code></pre>
<h3 id="二-子节点安装">二、子节点安装</h3>
<pre><code>

## 1, 安装etcd


## 2, 安装flannel


## 3, 安装kubernetes


## 4, 安装docker


</code></pre>
<h3 id="三验证集群状态">三.验证集群状态</h3>
<pre><code>1.master节点执行命令，查看端点信息
kubectl get endpoints

2.master节点执行命令，查看集群信息
kubectl cluster-info

3.master节点执行命令，获取节点信息
kubectl get nodes


## 部署app
kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080
kubectl run redis --image=docker.io/redis --port=6379

export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{&quot;\n&quot;}}{{end}}')
echo Name of the Pod: $POD_NAME

curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/


kubectl describe pods

kubectl  logs $POD_NAME

kubectl exec $POD_NAME env

kubectl exec -it $POD_NAME bash

kubectl get deployments

kubectl scale deployments/kubernetes-bootcamp --replicas=4

kubectl get pods -o wide

kubectl describe deployments/kubernetes-bootcamp

</code></pre>
<h3 id="其他">其他</h3>
<pre><code>######################
## 配置k8s repo
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
setenforce 0


yum install -y kubelet kubeadm kubectl
systemctl enable kubelet &amp;&amp; systemctl start kubelet

## 配置docker-ce repo
## 
# step 1: 安装必要的一些系统工具
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
# Step 2: 添加软件源信息
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# Step 3: 更新并安装 Docker-CE
sudo yum makecache fast
sudo yum -y install docker-ce
# Step 4: 开启Docker服务
sudo service docker start

注意：其他注意事项在下面的注释中
# 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。
# vim /etc/yum.repos.d/docker-ce.repo
#   将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[kubeadm部署k8s]]></title>
        <id>https://yes5144.github.io//post/kubeadm-bu-shu-k8s</id>
        <link href="https://yes5144.github.io//post/kubeadm-bu-shu-k8s">
        </link>
        <updated>2019-08-18T00:49:21.000Z</updated>
        <content type="html"><![CDATA[<h3 id=""></h3>
<pre><code>## https://www.bookstack.cn/read/kubernetes-handbook/SUMMARY.md
## https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/


</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql-主从复制]]></title>
        <id>https://yes5144.github.io//post/mysql-zhu-cong</id>
        <link href="https://yes5144.github.io//post/mysql-zhu-cong">
        </link>
        <updated>2019-08-11T03:39:01.000Z</updated>
        <content type="html"><![CDATA[<h3 id="mariadbmysql的主从复制部署docker">MariaDB/Mysql的主从复制部署(Docker)</h3>
<pre><code>### 原文链接：https://blog.csdn.net/clearlxj/article/details/88313033

### 注意文中有一个笔误： /home/lxj/hedisql  /home/lxj/heidisql/

## 修改master_my.cnf，在 [mysqld] 节点下添加

[mysqld]
server-id=1
log_bin=master-bin
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-ignore-db=test
innodb_flush_log_at_trx_commit=1
binlog_format=mixed


## 修改slave1_my.cnf，在 [mysqld] 节点下添加

[mysqld]
server-id=2
relay-log-index=slave-relay-bin.index
relay-log=slave-relay-bin
relay_log_recovery=1

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql-Docker部署mha]]></title>
        <id>https://yes5144.github.io//post/mysql-mha</id>
        <link href="https://yes5144.github.io//post/mysql-mha">
        </link>
        <updated>2019-08-11T03:23:04.000Z</updated>
        <content type="html"><![CDATA[<h3 id="docker搭建mariadbmysql-mha高可用集群">Docker搭建MariaDB/Mysql MHA高可用集群</h3>
<pre><code>原文链接：https://blog.csdn.net/clearlxj/article/details/88422206

## Checking if super_read_only is defined and turned on..DBD::mysql::st execute failed: Unknown system variable 'super_read_only' at /usr/share/perl5/vendor_perl/MHA/SlaveUtil.pm line 245.
报错原因：mha4mysql版本问题，
解决办法：最后将MHA的版本换成mha4mysql-0.56。

### mysql--docker化实践：https://blog.csdn.net/weixin_34290390/article/details/89123731
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql-GTID主从复制]]></title>
        <id>https://yes5144.github.io//post/mysql-gtid-zhu-cong</id>
        <link href="https://yes5144.github.io//post/mysql-gtid-zhu-cong">
        </link>
        <updated>2019-08-10T15:15:46.000Z</updated>
        <content type="html"><![CDATA[<h3 id="基于gtid-主从复制">基于gtid 主从复制</h3>
<pre><code>参考链接：https://blog.csdn.net/weixin_43407305/article/details/87911235
参考链接：https://blog.csdn.net/martingpf/article/details/81115187
参考链接：https://blog.csdn.net/leshami/article/details/50630691
参考链接：https://blog.csdn.net/qq_43094192/article/details/83994952

MySQL 5.6引入的GTID(Global Transaction IDs)使得其复制功能的配置、监控及管理变得更加易于实现，且更加健壮.

MySQL 5.6中使用复制功能，其服务配置段[mysqld]中于少应该定义如下选项：
binlog-format：二进制日志的格式，有row、statement和mixed几种类型；需要注意的是：当设置隔离级别为READ-COMMITED必 须设置二进制日志格式为ROW，现在MySQL官方认为STATEMENT这个已经不再适合继续使用,但mixed类型在默认的事务隔离级别下，可能会导致主从数据不一致；
log-slave-updates、gtid-mode、enforce-gtid-consistency、report-port和report-host：用于启动GTID及满足附属的其它需求；
master-info-repository和relay-log-info-repository：启用此两项，可用于实现在崩溃时保证二进制及从服务器安全的功能；
sync-master-info：启用之可确保无信息丢失；
slave-paralles-workers：设定从服务器的SQL线程数；0表示关闭多线程复制功能；
binlog-checksum、master-verify-checksum和slave-sql-verify-checksum：启用复制有关的所有校验功能；
binlog-rows-query-log-events：启用之可用于在二进制日志记录事件相关的信息，可降低故障排除的复杂度；
log-bin：启用二进制日志，这是保证复制功能的基本前提；
server-id：同一个复制拓扑中的所有服务器的id号必须惟一；

GTID的概念：
1）全局事务标识：global transaction identifiers。
2）GTID是一个事务一一对应，并且全局唯一ID。
3）一个GTID在一个服务器上只执行一次，避免重复执行导致数据混乱或者主从不一致。
4）GTID用来代替传统复制方法，不再使用MASTER_LOG_FILE+MASTER_LOG_POS开启复制。而是使用MASTER_AUTO_POSTION=1的方式开始复制。
5）MySQL-5.6.5开始支持的，MySQL-5.6.10后开始完善。
6）在传统的slave端，binlog是不用开启的，但是在GTID中slave端的binlog是必须开启的，目的是记录执行过的GTID（强制）。

GTID组成：
GTID = source_id:transaction_id
source_id，用于鉴别原服务器，即mysql服务器唯一的的server_uuid，由于GTID会传递到slave，所以也可以理解为源ID。
transaction_id，为当前服务器上已提交事务的一个序列号，通常从1开始自增长的序列，一个数值对应一个事务。        
示例：          
3E11FA47-71CA-11E1-9E33-C80AA9429562:23
前面的一串为服务器的server_uuid，即3E11FA47-71CA-11E1-9E33-C80AA9429562，后面的23为transaction_id

GTID原理：
1、当一个事务在主库端执行并提交时，产生GTID，一同记录到binlog日志中。
2、binlog传输到slave,并存储到slave的relaylog后，读取这个GTID的这个值设置gtid_next变量，即告诉Slave，下一个要执行的GTID值。
3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有该GTID。
4、如果有记录，说明该GTID的事务已经执行，slave会忽略。
5、如果没有记录，slave就会执行该GTID事务，并记录该GTID到自身的binlog，
   在读取执行事务前会先检查其他session持有该GTID，确保不被重复执行。
6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。

一、简单主从模式配置步骤
1、配置主从节点的服务配置文件
1.1、配置master节点：
[mysqld]
binlog-format=ROW
log-bin=master-bin
log-slave-updates=true  ###从服务器更新同步二进制日志信息，适用于高可用中，从服务器升级主服务器用
gtid-mode=on 
enforce-gtid-consistency=true
master-info-repository=TABLE
relay-log-info-repository=TABLE
sync-master-info=1
slave-parallel-workers=2
binlog-checksum=CRC32
master-verify-checksum=1
slave-sql-verify-checksum=1
binlog-rows-query-log_events=1
server-id=1
report-port=3306
port=3306
datadir=/mydata/
socket=/tmp/mysql.sock
report-host=edong1

1.2、配置slave节点：
[mysqld]
binlog-format=ROW
log-slave-updates=true
gtid-mode=on 
enforce-gtid-consistency=true
master-info-repository=TABLE
relay-log-info-repository=TABLE
sync-master-info=1
slave-parallel-workers=2
binlog-checksum=CRC32
master-verify-checksum=1
slave-sql-verify-checksum=1
binlog-rows-query-log_events=1
server-id=11
report-port=3306
port=3306
log-bin=mysql-bin.log
datadir=/mydata/
socket=/tmp/mysql.sock
report-host=edong2
slave节点配置和master节点配置一样的目的：主服务器挂了，从服务器可以快速升级为主服务器
2、创建复制用户
mysql&gt;grant replication slave on *.* to 'repluser'@'192.168.0.%' identified by 'replpassword';
3、为备节点提供初始数据集
锁定主表，备份主节点上的数据，将其还原至从节点；如果没有启用GTID，在备份时需要在master上使用show master status命令查看二进制日志文件名称及事件位置，以便后面启动slave节点时使用。
4、启动从节点的复制线程
如果启用了GTID功能，则使用如下命令：
mysql&gt;change master to master_host='192.168.0.202',master_user='repluser',master_password='replpassword',master_auto_position=1;

半同步复制

1、分别在主从节点上安装相关的插件
master&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
slave&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';

2、启用半同步复制
在master上的配置文件中，添加
rpl_semi_sync_master_enabled=ON
在至少一个slave节点的配置文件中添加
rpl_semi_sync_slave_enabled=ON
而后重新启动mysql服务即可生效。

或者，也可以mysql服务上动态启动其相关功能：
master&gt; SET GLOBAL rpl_semi_sync_master_enabled = ON;
slave&gt; SET GLOBAL rpl_semi_sync_slave_enabled = ON;
slave&gt; STOP SLAVE IO_THREAD; START SLAVE IO_THREAD;

3、确认半同步功能已经启用
master&gt; CREATE DATABASE magedudb;
master&gt; SHOW STATUS LIKE 'Rpl_semi_sync_master_yes_tx';

slave&gt; SHOW DATABASES;

</code></pre>
<h3 id="主从复制">主从复制</h3>
<pre><code>主从复制过程存在三个线程，Master端的I/O线程，Slave的I/O线程与SQL线程。Master端需要开启binlog日志，Slave端需要开启relaylog。
1、Slave端的I/O读取master.info文件，获取binlog文件名和位置点，然后向Master端的I/O线程请求，该binlog文件名和位置点的binlog信息。
（master.info文件在配置主从复制时使用change master命令来指定生成）
2、Master端的I/O线程会根据Slave端的I/O线程请求的信息来读取Master的binlog日志信息与及读取到最新的binlog文件名和位置点一同返回给Slave的I/O线程。
3、Slave端的I/O线程会把获取到的binlog日志写入relaylog（中继日志）文件中，并且更新master.info文件信息。（把读取到Master最新的binlog日志文件名和位置点更新到master.info文件中，下一次当前位置去读取Master的binlog日志）
4、Slave端的SQL线程会定期读取relaylog，把二进制的日志解析成SQL语句，并执行这些SQL语句，同步数据到从库中

原文链接：https://blog.csdn.net/weixin_43407305/article/details/87911235
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s 学习]]></title>
        <id>https://yes5144.github.io//post/k8s-xue-xi</id>
        <link href="https://yes5144.github.io//post/k8s-xue-xi">
        </link>
        <updated>2019-08-08T16:12:07.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1docker的安装">1，docker的安装</h3>
<pre><code>## 使用阿里云镜像加速安装下载docker-ce
## 参考链接：https://yq.aliyun.com/articles/110806

# step 1: 安装必要的一些系统工具
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
# Step 2: 添加软件源信息
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# Step 3: 更新并安装 Docker-CE
sudo yum makecache fast
sudo yum -y install docker-ce
# Step 4: 开启Docker服务
sudo service docker start

</code></pre>
<h3 id="2配置-docker-加速器">2，配置 docker 加速器</h3>
<pre><code>## 参考链接https://www.daocloud.io/mirror
## 该脚本可以将 --registry-mirror 加入到你的 Docker 配置文件 /etc/docker/daemon.json 中。适用于 Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同。更多详情请访问文档。
curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io



</code></pre>
<h3 id="5k8s基础命令">5，k8s基础命令</h3>
<pre><code>## https://kubernetes.io/docs/tutorials/

## 
kubectl  get  nodes
kubectl  cluster-info
## deployment
kubectl  run kubernetes-bootcamp  --image=docker.io/jocatalin/kubernetes-bootcamp:v1  --port=8080
kubectl  get  nodes
## 
kubectl  expose  deployment/kubernets-bootcamp  --type=&quot;NodePort&quot;  --port=8080
kubectl  get  services

kubectl delete service -l run=kubernetes-bootcamp
kubectl get services

## scale
kubectl  get  deployments
kubectl  scale  deployments/kubernetes-bootcamp  --replicas=3
kubectl  get  deployments
kubectl  get  nodes

kubectl  scale  deployments/kubernetes-bootcamp  --replicas=2
kubectl  get  deployments
kubectl  get  nodes

## 
kubectl  set  image  deployments/kubernetes-bootcamp  kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2

kubectl  rollout  undo  deployments/kubernetes-bootcamp
kubectl  get  nodes

kubectl  get  namespace

</code></pre>
<h3 id="kubectl-管理应用程序生命周期">kubectl 管理应用程序生命周期</h3>
<pre><code>1、创建
kubectl run nginx --replicas=3 --image=nginx:1.14 --port=80
kubectl get deploy,pods

2、发布
kubectl expose deployment nginx --port=80  --type=NodePort  --target-port=80  --name=nginx-service
kubectl  get service

3、更新
kubectl  set image deployment/nginx  nginx=nginx:1.15

4、回滚
kubectl rollout history deployment/nginx
kubectl rollout undo deployment/nginx

5、删除
kubectl  delete deploy/nginx
kubectl  delete svc/nginx-service

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 解压缩命令]]></title>
        <id>https://yes5144.github.io//post/linux-jie-ya-suo-ming-ling</id>
        <link href="https://yes5144.github.io//post/linux-jie-ya-suo-ming-ling">
        </link>
        <updated>2019-08-07T23:23:04.000Z</updated>
        <content type="html"><![CDATA[<h3 id="不解压缩查看压缩包内文件列表">不解压缩，查看压缩包内文件列表</h3>
<pre><code>tar -ztvf file.tar.gz

tar.gz
tar tzvf xxx.tar.gz

tar.bz2
tar tjvf xxx.tar.bz2

zip
unzip -l xxx.zip  (简略模式)
unzip -v xxx.zip (详细模式)

rar
unrar l xxx.rar(简略模式)
unrar v xxx.rar(详细模式)

 

linux压缩和解压缩命令大全

tar命令

　　解包：tar zxvf FileName.tar

　　打包：tar czvf FileName.tar DirName

gz命令

　　解压1：gunzip FileName.gz

　　解压2：gzip -d FileName.gz

　　压缩：gzip FileName

　　.tar.gz 和 .tgz

　　解压：tar zxvf FileName.tar.gz

　　压缩：tar zcvf FileName.tar.gz DirName

   压缩多个文件：tar zcvf FileName.tar.gz DirName1 DirName2 DirName3 ...

bz2命令

　　解压1：bzip2 -d FileName.bz2

　　解压2：bunzip2 FileName.bz2

　　压缩： bzip2 -z FileName

　　.tar.bz2

　　解压：tar jxvf FileName.tar.bz2

　　压缩：tar jcvf FileName.tar.bz2 DirName

bz命令

　　解压1：bzip2 -d FileName.bz

　　解压2：bunzip2 FileName.bz

　　压缩：未知

　　.tar.bz

　　解压：tar jxvf FileName.tar.bz

Z命令

　　解压：uncompress FileName.Z

　　压缩：compress FileName

　　.tar.Z

　　解压：tar Zxvf FileName.tar.Z

　　压缩：tar Zcvf FileName.tar.Z DirName

zip命令

　　解压：unzip FileName.zip

　　压缩：zip FileName.zip DirName

rar命令

　　解压：rar a FileName.rar

　　压缩：r ar e FileName.rar
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Promql 查询语法]]></title>
        <id>https://yes5144.github.io//post/promql-cha-xun-yu-fa</id>
        <link href="https://yes5144.github.io//post/promql-cha-xun-yu-fa">
        </link>
        <updated>2019-07-28T14:51:12.000Z</updated>
        <content type="html"><![CDATA[<h3 id="首先部署一套prometheus访问9090端口">首先部署一套prometheus，访问9090端口</h3>
<pre><code>https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-query-language
## 简单使用
http_requests_total{code=&quot;200&quot;,handler=&quot;alerts&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;}=(20889@1518096812.326)
http_requests_total{code=&quot;200&quot;,handler=&quot;graph&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;}=(21287@1518096812.326)

## 支持正则表达式
http_requests_total{environment=~&quot;staging|testing|development&quot;,method!=&quot;GET&quot;}

## 查询范围
http_request_total{}[5m]
http_request_total{} # 瞬时向量表达式，选择当前最新的数据
http_request_total{}[5m] # 区间向量表达式，选择以当前时间为基准，5分钟内的数据

## 聚合操作
# 查询系统所有http请求的总量
sum(http_request_total)

# 按照mode计算主机CPU的平均使用时间
avg(node_cpu) by (mode)

# 按照主机查询各个主机的CPU使用率
sum(sum(irate(node_cpu{mode!='idle'}[5m]))  / sum(irate(node_cpu[5m]))) by (instance)

# top 5
topk(5, http_requests_total)

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grafana + zabbix 打造监控大屏]]></title>
        <id>https://yes5144.github.io//post/grafana-zabbix-da-zao-jian-kong-da-ping</id>
        <link href="https://yes5144.github.io//post/grafana-zabbix-da-zao-jian-kong-da-ping">
        </link>
        <updated>2019-07-28T13:47:49.000Z</updated>
        <content type="html"><![CDATA[<h3 id="每天看着zabbix展示界面是不是有点腻歪了要不要换个高大上提升一下逼格">每天看着zabbix展示界面是不是有点腻歪了，要不要换个高大上提升一下逼格？？？</h3>
<p>参考链接：</p>
<pre><code>## 分布式监控系统Zabbix--使用Grafana进行图形展示
https://www.cnblogs.com/kevingrace/p/7108060.html
## 10分钟打造炫酷的监控大屏
http://www.ywjt.org/index.php/archives/1802
## 徒手教你制作运维监控大屏
https://www.cnblogs.com/zhangs1986/p/11180694.html
## 官方地址：http://docs.grafana-zabbix.org
## 项目Demo：http://play.grafana.org/
## 项目github：https://github.com/grafana/grafana
</code></pre>
<h3 id="当你耐心看完如上链接相信已经差不多ok了下面只是我的坑友情提示一下">当你耐心看完如上链接，相信已经差不多OK了，下面只是我的坑友情提示一下：</h3>
<h4 id="1由于本人采用的是tar包解压的方式启动所以plugins在安装目录的dataplugins你可以修改配置文件重新指向varlibgrafanaplugins">1，由于本人采用的是tar包解压的方式启动，所以plugins在安装目录的data/plugins/，你可以修改配置文件重新指向/var/lib/grafana/plugins/</h4>
<pre><code>## 获取可用插件列表
grafana-cli plugins list-remote
 
## 安装zabbix插件
grafana-cli plugins install alexanderzobnin-zabbix-app
 
## 安装插件完成之后重启garfana服务
service grafana-server restart

## 安装其他图形插件
# 饼图展示
grafana-cli plugins install grafana-piechart-panel
#钟表形展示
grafana-cli plugins install grafana-clock-panel
grafana-cli plugins install briangann-gauge-panel
#字符型展示
grafana-cli plugins install natel-discrete-panel
#服务器状态
grafana-cli plugins install vonage-status-panel
</code></pre>
<h4 id="2在grafana官网找一个zabbix插件稍稍修改应用">2，在grafana官网找一个zabbix插件，稍稍修改应用</h4>
<pre><code>https://grafana.com/grafana/dashboards/6098

</code></pre>
<h4 id="有兴趣开发一个grafana插件">有兴趣开发一个grafana插件</h4>
<p>https://juejin.im/post/5addbcbd5188256715474452</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git和Svn 差异化打包]]></title>
        <id>https://yes5144.github.io//post/git-he-svn-chai-yi-hua-da-bao</id>
        <link href="https://yes5144.github.io//post/git-he-svn-chai-yi-hua-da-bao">
        </link>
        <updated>2019-07-18T15:40:26.000Z</updated>
        <content type="html"><![CDATA[<h3 id="git">Git</h3>
<pre><code>git diff这个命令能比较两个提交之间的差异，使用–name-only参数可以只显示文件名。例如：

git diff 608e120 4abe32e --name-only

打包差异文件
git diff 608e120 4abe32e --name-only | xargs zip update.zip

备注：608e120和4abe32e为前后两个提交的commit id

原文：https://blog.csdn.net/liuxinfa/article/details/82878640 
</code></pre>
<h3 id="svn">Svn</h3>
<pre><code>最近接手一个PHP项目，修复GUG和优化功能，由于是已经在用的项目，并且诸如附件上传都是保存到WEB目录下的，

所以不宜采用全量部署的方式来更新软件，最好用增量部署来更新服务器的WEB目录。

程序代码采用SVN管理，在主干上开发，每次部署都建一个tag，这样通过比较tag和主干的差别就可以知道有哪些文件发生了变动。具体的命令格式是： 

svn diff --summarize http://rep_url/tags/proj1_090214 http://rep_url/trunk/proj1 &gt;diff.txt

这个命令比较了 proj1_090214 和 proj1 的差异，并将差异信息输出到文件 diff.txt
summarize  选项的含义是只显示结果的概要，不显示文件的具体差异。

有了diff.txt，就可以知道需要部署哪些文件了，感觉很方便

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[沉迷学习]]></title>
        <id>https://yes5144.github.io//post/chen-mi-xue-xi</id>
        <link href="https://yes5144.github.io//post/chen-mi-xue-xi">
        </link>
        <updated>2019-07-18T01:00:32.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>Python</li>
<li>Django</li>
<li>Golang</li>
<li>Beego</li>
<li>Docker</li>
<li>K8s</li>
<li>Linux架构师</li>
<li>chinaielts</li>
</ul>
<pre><code>## python
https://github.com/jackfrued/Python-100-Days

## k8s
https://github.com/opsnull/follow-me-install-kubernetes-cluster

## beego
https://www.jianshu.com/nb/27703855
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Go 开发环境部署]]></title>
        <id>https://yes5144.github.io//post/go-kai-fa-huan-jing-bu-shu</id>
        <link href="https://yes5144.github.io//post/go-kai-fa-huan-jing-bu-shu">
        </link>
        <updated>2019-07-16T15:14:03.000Z</updated>
        <content type="html"><![CDATA[<h4 id="依赖包在golangorg">依赖包在golang.org ???</h4>
<pre><code>git clone https://github.com/golang/net.git $GOPATH/src/github.com/golang/net
git clone https://github.com/golang/sys.git $GOPATH/src/github.com/golang/sys
git clone https://github.com/golang/tools.git $GOPATH/src/github.com/golang/tools
git clone https://github.com/golang/sync.git $GOPATH/src/github.com/golang/sync
git clone https://github.com/golang/lint.git $GOPATH/src/github.com/golang/lint
git clone https://github.com/golang/text.git $GOPATH/src/github.com/golang/text

mkdir -p  $GOPATH/src/golang.org/x
cp -a $GOPATH/src/github.com/golang/  $GOPATH/src/golang.org/x

go get -v github.com/rogpeppe/godef
go get -v github.com/mdempsky/gocode
go get -v github.com/stamblerre/gocode
go get -v golang.org/x/tools/cmd/goimports
go get -v github.com/ramya-rao-a/go-outline
go get -v golang.org/x/tools/cmd/gopls
go get -u github.com/spf13/cobra/cobra

</code></pre>
<h4 id="vscode-go代码补全">vscode go代码补全</h4>
<pre><code>https://maiyang.me/post/2018-09-14-tips-vscode/
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL 请空表]]></title>
        <id>https://yes5144.github.io//post/mysql-qing-kong-biao</id>
        <link href="https://yes5144.github.io//post/mysql-qing-kong-biao">
        </link>
        <updated>2019-07-15T15:31:53.000Z</updated>
        <content type="html"><![CDATA[<pre><code>SET FOREIGN_KEY_CHECKS = 0;
TRUNCATE `events`;
TRUNCATE `problem`;

set FOREIGN_key_checks =1;
</code></pre>
]]></content>
    </entry>
</feed>